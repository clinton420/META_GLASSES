{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b01d6b-8c48-4204-ac8c-9d2f095f1aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in c:\\users\\swaro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\swaro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from groq) (2.9.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\swaro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from groq) (0.27.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\swaro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from groq) (4.6.2.post1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\swaro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\swaro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\swaro\\appdata\\roaming\\python\\python310\\site-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\swaro\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\swaro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\swaro\\appdata\\roaming\\python\\python310\\site-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\swaro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\swaro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\swaro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\swaro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\swaro\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\swaro\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\swaro\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\swaro\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\swaro\\appdata\\roaming\\python\\python310\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f9efd15-374c-4085-925b-6a41848292b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sounddevice in c:\\users\\swaro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\swaro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.14.1)\n",
      "Requirement already satisfied: ffmpeg-python in c:\\users\\swaro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\swaro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sounddevice) (1.17.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in c:\\users\\swaro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scipy) (1.26.4)\n",
      "Requirement already satisfied: future in c:\\users\\swaro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ffmpeg-python) (1.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\swaro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from CFFI>=1.0->sounddevice) (2.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\swaro\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\swaro\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\swaro\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\swaro\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\swaro\\appdata\\roaming\\python\\python310\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install sounddevice scipy ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a828bd9e-d17f-4296-ae81-eb11ed325b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import ffmpeg\n",
    "from scipy.io.wavfile import write\n",
    "from groq import Groq\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd234b8c-9e08-4de7-8d46-e1e06f2c7dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Groq client\n",
    "client = Groq()\n",
    "\n",
    "# Parameters for recording and transcription\n",
    "duration = 3  # Duration of each recording in seconds\n",
    "sample_rate = 44100  # Sample rate\n",
    "wav_filename = \"temp_audio.wav\"  # Temporary .wav file path\n",
    "m4a_filename = \"temp_audio.m4a\"  # Temporary .m4a file path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35d7a19f-3bd7-4b07-a429-6d4123159db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting real-time transcription... Press 'Ctrl+C' to end.\n",
      "Transcription:  Can you tell me what I am holding?\n",
      "Stopping transcription due to unclear audio.\n",
      "All transcriptions saved to transcription_output.txt\n",
      "Status Code: 200\n",
      "Response JSON: {'answer': \"Question: Can you tell me what I am holding?/n context: the user is watching a human torso physical model Heart\\nProvide a detailed educational answer: \\n\\nThe human torso physical model heart is a visual aid used to illustrate the anatomy of the heart. It is a three-dimensional representation of the heart, typically made of plastic or foam, and is designed to be held in the user's hand. The model heart is usually a simplified representation of the heart, showing the main chambers and structures, such as the atria, ventricles, and septum.\\n\\nWhen holding the model heart, you can observe the following features:\\n\\n* The atria are the upper chambers of the heart, which receive blood from the veins. They are typically represented by the two upper chambers of the model heart.\\n* The ventricles are the lower chambers of the heart, which pump blood to the rest of the body. They are typically represented by the two lower chambers of the model heart.\\n* The septum is the wall of tissue that separates the atria and ventricles. It is typically represented by a thin wall or partition between the atrial and vent\", 'instruction': \"Please reply with 'i got it' when you understand the answer.\", 'response_type': 'answer'}\n",
      "LLaMA Response:  No response from LLaMA\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "run loop already started",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 121\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 121\u001b[0m     \u001b[43msend_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# prompt = whisper_content + \"/n context: the user is watching a human torso physical model \" + yolov_output_content + \"/n Also tellparts of it\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# stream = client.chat.completions.create(\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# engine.say(data)\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# engine.runAndWait()\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[47], line 115\u001b[0m, in \u001b[0;36msend_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m    113\u001b[0m     engine \u001b[38;5;241m=\u001b[39m pyttsx3\u001b[38;5;241m.\u001b[39minit()\n\u001b[0;32m    114\u001b[0m     engine\u001b[38;5;241m.\u001b[39msay(data)\n\u001b[1;32m--> 115\u001b[0m     \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunAndWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError from API: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyttsx3\\engine.py:180\u001b[0m, in \u001b[0;36mEngine.runAndWait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03mRuns an event loop until all commands queued up until this method call\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03mcomplete. Blocks during the event loop and returns when the queue is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m@raise RuntimeError: When the loop is already running\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inLoop:\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun loop already started\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inLoop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_driverLoop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: run loop already started"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pyttsx3\n",
    "output_file = \"transcription_output.txt\"  # File to save all transcriptions\n",
    "transcriptions = []  # Store all transcription results\n",
    "\n",
    "print(\"Starting real-time transcription... Press 'Ctrl+C' to end.\")  # Updated to reflect keyboard shortcut for stopping\n",
    "try:\n",
    "    while True:\n",
    "        # Step 1: Record audio for the specified duration\n",
    "        audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=2, dtype='int16')\n",
    "        sd.wait()  # Wait until recording is finished\n",
    "        \n",
    "        # Save recorded audio to a temporary .wav file\n",
    "        wav_filename = \"temp_recording.wav\"  # Ensure temporary file has a consistent name\n",
    "        write(wav_filename, sample_rate, audio_data)\n",
    "        \n",
    "        # Step 2: Convert .wav to .m4a using ffmpeg\n",
    "        m4a_filename = \"temp_recording.m4a\"  # Ensure temporary m4a file has a consistent name\n",
    "        ffmpeg.input(wav_filename).output(m4a_filename).run(overwrite_output=True)\n",
    "\n",
    "        # Step 3: Transcribe the .m4a file\n",
    "        with open(m4a_filename, \"rb\") as file:\n",
    "            transcription = client.audio.transcriptions.create(\n",
    "                file=(m4a_filename, file.read()),  # Audio file for transcription\n",
    "                model=\"whisper-large-v3-turbo\",\n",
    "                response_format=\"json\",\n",
    "                language=\"en\",\n",
    "                temperature=0.0\n",
    "            )\n",
    "            # Get the transcription text\n",
    "            transcribed_text = transcription.text\n",
    "            print(\"Transcription:\", transcribed_text)\n",
    "            transcriptions.append(transcribed_text)  # Append to the list\n",
    "\n",
    "            # Check for undesired output patterns to stop recording\n",
    "            if \".\" or \"I don’t understand\" in transcribed_text or \"I can't understand\" in transcribed_text:\n",
    "                print(\"Stopping transcription due to unclear audio.\")\n",
    "                break  # Exit the loop\n",
    "\n",
    "        # Small delay to avoid immediate re-recording\n",
    "        time.sleep(0.5)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nReal-time transcription ended by user.\")\n",
    "\n",
    "finally:\n",
    "    # Save all transcriptions to a text file\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(\"\\n\".join(transcriptions))\n",
    "    print(f\"All transcriptions saved to {output_file}\")\n",
    "\n",
    "    # Cleanup: remove temporary files\n",
    "    if os.path.exists(wav_filename):\n",
    "        os.remove(wav_filename)\n",
    "    if os.path.exists(m4a_filename):\n",
    "        os.remove(m4a_filename)\n",
    "\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq()\n",
    "# Open and read the content of Yolov_output.txt\n",
    "with open('Yolov_output.txt', 'r') as file:\n",
    "    yolov_output_content = file.read()\n",
    "    \n",
    "\n",
    "with open('transcription_output.txt', 'r') as file:\n",
    "    whisper_content = file.read()\n",
    "\n",
    "# prompt = whisper_content + \"\\n Context: the user is looking at:\" + yolov_output_content\n",
    "prompt = whisper_content + \"/n context: the user is watching a human torso physical model \" + yolov_output_content\n",
    "\n",
    "# print(prompt)\n",
    "import requests\n",
    "import re\n",
    "cleaned_text = prompt.lstrip(' ')\n",
    "cleaned_text1 = cleaned_text.lstrip(' \\t')\n",
    "\n",
    "\n",
    "# Remove spaces and tabs\n",
    "cleaned_text1 = cleaned_text.lstrip(' \\t')\n",
    "\n",
    "if \"Option\" in  cleaned_text1:\n",
    "    cleaned_text1 = \"A\"\n",
    "    \n",
    "def send_data():\n",
    "    # URL of the Flask API\n",
    "    url = \"http://195.242.13.130:2025/receive\"\n",
    "    \n",
    "    # JSON payload to send\n",
    "    payload = {\n",
    "\n",
    "        \"message\": cleaned_text1\n",
    "    }\n",
    "    \n",
    "    # Headers to specify content type\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # Sending POST request\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    \n",
    "    # Print the response\n",
    "    print(\"Status Code:\", response.status_code)\n",
    "    print(\"Response JSON:\", response.json())\n",
    "    if response.status_code == 200:\n",
    "    # Extract the LLaMA response from the JSON\n",
    "        data = response.json()\n",
    "        llama_response = data.get(\"llama_response\", \"No response from LLaMA\")\n",
    "        print(\"LLaMA Response: \", llama_response)\n",
    "    # Convert the text response to speech using pyttsx3\n",
    "        engine = pyttsx3.init()\n",
    "        engine.say(data)\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        print(f\"Error from API: {response.status_code}\")\n",
    "        print(response.text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    send_data()\n",
    "\n",
    "# prompt = whisper_content + \"/n context: the user is watching a human torso physical model \" + yolov_output_content + \"/n Also tellparts of it\"\n",
    "\n",
    "# stream = client.chat.completions.create(\n",
    "#     #\n",
    "#     # Required parameters\n",
    "#     #\n",
    "#     messages=[\n",
    "#         # Set an optional system message. This sets the behavior of the\n",
    "#         # assistant and can be used to provide specific instructions for\n",
    "#         # how it should behave throughout the conversation.\n",
    "#         {\n",
    "#             \"role\": \"system\",\n",
    "#             \"content\": \"just tell what user is looking at by context\"\n",
    "#         },\n",
    "#         # Set a user message for the assistant to respond to.\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": prompt,\n",
    "#         }\n",
    "#     ],\n",
    "\n",
    "#     # The language model which will generate the completion.\n",
    "#     model=\"llama3-8b-8192\",\n",
    "\n",
    "#     #\n",
    "#     # Optional parameters\n",
    "#     #\n",
    "\n",
    "#     # Controls randomness: lowering results in less random completions.\n",
    "#     # As the temperature approaches zero, the model will become deterministic\n",
    "#     # and repetitive.\n",
    "#     temperature=0.5,\n",
    "\n",
    "#     # The maximum number of tokens to generate. Requests can use up to\n",
    "#     # 2048 tokens shared between prompt and completion.\n",
    "#     max_tokens=1024,\n",
    "\n",
    "#     # Controls diversity via nucleus sampling: 0.5 means half of all\n",
    "#     # likelihood-weighted options are considered.\n",
    "#     top_p=1,\n",
    "\n",
    "#     # A stop sequence is a predefined or user-specified text string that\n",
    "#     # signals an AI to stop generating content, ensuring its responses\n",
    "#     # remain focused and concise. Examples include punctuation marks and\n",
    "#     # markers like \"[end]\".\n",
    "#     stop=None,\n",
    "\n",
    "#     # If set, partial message deltas will be sent.\n",
    "#     stream=True,\n",
    "# )\n",
    "\n",
    "# # Print the incremental deltas returned by the LLM.\n",
    "# data = []\n",
    "# for chunk in stream:\n",
    "#     if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None:\n",
    "#         text = chunk.choices[0].delta.content\n",
    "#         data.append(text)\n",
    "#         print(text, end=\"\", flush=True)\n",
    "# data = \"\".join(filter(None, data))\n",
    "\n",
    "\n",
    "# engine = pyttsx3.init()\n",
    "# engine.say(data)\n",
    "# engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40558e6f-5b29-4f52-8487-533c6cd7b728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30326b35-677d-43d6-a36b-808e4ee1707c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
